import os
import numpy as np
import yaml
import cv2
import open3d as o3d

from PIL import Image
from skimage.transform import resize
from RTAB_utils.spatQuad import SpatQuadranion


class RTAB2Cache():
    def __getIntrinsic(self, clib_file):
        """_summary_
            This is to get intrinsic values produced by the RTAB output.
            Input to this file requires YAML produced by RTAB
        
        Args:
            clib_file (String): Path to the RTAB Camera YAML file

        Returns:
            np.ndarray: [3, 3]: 3 X 3 Camera Matrix
        """
        with open(clib_file) as infile:
            for i in range(2):
                _ = infile.readline()
            data = yaml.safe_load(infile)
        return np.reshape(data['camera_matrix']['data'], (3,3))

    def __init__(self, data_path, rgb_dir, depth_dir, pose_file , startf, stopf, stepf, relative = False, padding = False) -> None:
        """_summary_
            Initialisation function sets default parameters and variables.
        
        Args:
            data_path (String): Path to the exported data from RTAB
        """
        self.data_path = data_path
        self.startf = startf
        self.stopf = stopf
        self.stepf = stepf
        self.relative = relative
        self.padding = padding
        self.rgb_path = rgb_dir
        self.depth_path = depth_dir
        self.pose_file = pose_file
        #self.pose_file_raw = os.path.join(self.data_path, '_poses_raw.txt')
        self.intrinsic = self.__getIntrinsic(clib_file= 'RTAB_utils' + os.sep +'calibration.yaml')
    
    def __readOdometry(self):
        """_summary_
            Read Pose text file generated by RTAB
            Process for exporting
            Export poses... -> RGBD Slam + ID Format (.txt) -> Camera

        Returns:
            np.ndarray: [1, n]: Exports Image IDs used in reconstruction of SLAM
            np.ndarray: [3, n]: Exports translation occured WRT to base frame during reconstruction of SLAM
            np.ndarray: [4, n]: Exports rotation occured WRT to base frame during reconstruction of SLAM [X, Y, Z, W]
            np.ndarray: [1, n]: Exports timedata for each frame captured
        """
        pose = np.genfromtxt(self.pose_file, delimiter=" ")
        #pose = pose[:50]
        pose = pose[self.startf: self.stopf]
        img_idx = np.asarray(pose[:,8])
        odo_xyz = np.asarray(pose[:,1:4])
        odo_wxyz = np.asarray(pose[:,4:8])
        odo_timestamp = np.asarray(pose[:, 0])
        return img_idx, odo_xyz, odo_wxyz, odo_timestamp

    '''def __readOdometryRAW(self):
        """_summary_
            Read Pose text file generated by RTAB
            Process for exporting
            Export poses... -> RAW Format (*.txt) -> Camera

        Returns:
            np.ndarray: [3, n]: Exports translation occured WRT to base frame during reconstruction of SLAM
            np.ndarray: [4, n]: Exports rotation occured WRT to base frame during reconstruction of SLAM
        """
        pose = np.genfromtxt(self.pose_file_raw, delimiter=" ")
        odo_tr = np.asarray(pose[:,0:3])
        odo_rot = np.asarray(pose[:,3:12])
        return  odo_tr, odo_rot'''

    def __readRGB(self):
        """_summary_
            Read RGB images provided with the data_path

        Returns:
            np.ndarray: [h, w, d]: image.shape: RGB array of the image
        """
        images = []
        for imgx in self.img_idx:
            images.append(np.asarray(Image.open(self.rgb_path + os.sep + str(int(imgx)) + ".jpg")))
        return images

    def __readDepth(self):
        """_summary_
            Read Depth images provided with the data_path

        Returns:
            np.ndarray: [h, w]: depth.shape: Depth array of the image
        """
        depth = []
        if self.padding:
            refImg = np.asarray(Image.open(self.depth_path + os.sep + str(int(self.img_idx[0])) + ".png"))
            padding = cv2.copyMakeBorder(np.ones((refImg.shape[0]-20, refImg.shape[1]-20)), 10, 10, 10, 10, cv2.BORDER_CONSTANT, None, value = 0)
            for imgx in self.img_idx:
                depth.append(np.multiply(np.asarray(Image.open(self.depth_path + os.sep + str(int(imgx)) + ".png")), padding))
        else:
            for imgx in self.img_idx:
                depth.append(np.asarray(Image.open(self.depth_path + os.sep + str(int(imgx)) + ".png")))
        return depth
    
    def __resize_camera_matrix(self, scale_x, scale_y):
        """_summary_

        Args:
            scale_x (float): Camera Param Cx
            scale_y (float): Camera Param Cy

        Returns:
            np.ndarray: [3, 3]: 3 X 3 Scaled Camera Matrix
        """
        fx = self.intrinsic[0, 0]
        fy = self.intrinsic[1, 1]
        cx = self.intrinsic[0, 2]
        cy = self.intrinsic[1, 2]
        return np.array([[fx * scale_x, 0.0, cx * scale_x],
            [0., fy * scale_y, cy * scale_y],
            [0., 0., 1.0]])

    def __globalRT2Local(self):
        """_summary_
            This function converts Global Rotation and Translation i.e 
            From: Frame No: 0:1, 0:2, 0:3 ..... 0:n
            To Local R,t  : Frame No: 0:1, 1:2, 2:3 ..... n-1:n 

        Returns:
            np.ndarray: [3, n]: Exports translation occured WRT to previous frame during reconstruction of SLAM
            np.ndarray: [4, n]: Exports rotation occured WRT to previous frame during reconstruction of SLAM [X, Y, Z, W]
        """
        loc_xyz  = []
        loc_wxyz = []
        loc_wxyz.append(self.odo_wxyz[0])
        loc_xyz.append(self.odo_xyz[0])
        for i in range(1, len(self.odo_wxyz)):
            loc_xyz.append(self.odo_xyz[i] - self.odo_xyz[i-1])
            qz = SpatQuadranion(str(self.odo_wxyz[i][3]), str(self.odo_wxyz[i][0]), str(self.odo_wxyz[i][1]), str(self.odo_wxyz[i][2])) / SpatQuadranion(str(self.odo_wxyz[i-1][3]), str(self.odo_wxyz[i-1][0]), str(self.odo_wxyz[i-1][1]), str(self.odo_wxyz[i-1][2]))
            loc_wxyz.append([qz[1], qz[2], qz[3], qz[0]])
        print(loc_wxyz)
        print(np.reshape(loc_wxyz, self.odo_wxyz.shape))
        return loc_xyz, np.reshape(loc_wxyz, self.odo_wxyz.shape)

    def __getRGBP3d(self):
        """_summary_
            Get the Data 3D point and corresponding RGB data

        Returns:
            np.ndarray: [tot_frames, 3, n]: Exports 3D points converted from Depth Image
            np.ndarray: [tot_frames, 3, n]: Exports RGB data for corresponding 3D points
        """
        org_ptx = []
        color_data = []
        RGB_HEIGHT, RGB_WIDTH, _ = self.RGB_res
        Depth_HEIGHT, Depth_WIDTH = self.Depth_res
        self.intrinsics_scaled = self.__resize_camera_matrix(Depth_WIDTH / RGB_WIDTH, Depth_HEIGHT / RGB_HEIGHT)
        pixel_x,pixel_y = np.meshgrid(np.linspace(0,Depth_WIDTH-1,Depth_WIDTH),
                                    np.linspace(0,Depth_HEIGHT-1,Depth_HEIGHT))
        for i in range(len(self.depths)):
            camera_points_x = np.multiply(pixel_x-self.intrinsics_scaled[0,2], self.depths[i] / self.intrinsics_scaled[0,0])
            camera_points_y = np.multiply(pixel_y-self.intrinsics_scaled[1,2], self.depths[i] / self.intrinsics_scaled[1,1])
            org_ptx.append(np.array([camera_points_x, camera_points_y, self.depths[i]]).transpose(1,2,0).reshape(-1,3))
            rgb_data = np.asarray(self.images[i], dtype = "uint8")
            rgb_data = resize(rgb_data, self.Depth_res)
            color_data.append(rgb_data.reshape(-1,3))
        return org_ptx, color_data

    def __getModP3d(self):
        """Get the 3d points modified according to provided rotation and translation

        Returns:
            np.ndarray: [tot_frames, 3, n]: Exports 3D points converted WRT R,t
        """
        self.orig_ptx = np.divide(self.orig_ptx, 1000)
        mod_ptx = []
        for i in range(len(self.orig_ptx)):
            rot = SpatQuadranion(str(self.odo_wxyz[i][3]), str(self.odo_wxyz[i][0]), str(self.odo_wxyz[i][1]), str(self.odo_wxyz[i][2]))
            new_ptx = rot.rotate(self.orig_ptx[i])
            new_ptx = new_ptx + self.odo_xyz[i]
            mod_ptx.append(new_ptx)
        return mod_ptx
    
    def __getNomals(self,frame_points):
        """Given 3D points and camera location get points normals

        Args:
            frame_points (ndarray)np.ndarray: [tot_frames, 3, n]: Exported 3D points

        Returns:
            np.ndarray: [tot_frames, 3, n]: Normals of the 3D input points
        """
        normals = []
        for i in range(len(self.odo_xyz)):
            normals.append(self.odo_xyz[i] - frame_points[i])
        return normals

    def __getRTABConvertData(self):
        """Main Function that gets RTAB data
            conversion to tooliqa data format
            Path to the exported data from RTAB is required.

        Returns:
            np.ndarray: [1, n]: Exports Image IDs used in reconstruction of SLAM
            np.ndarray: [3, n]: Exports translation occured WRT to base frame during reconstruction of SLAM
            np.ndarray: [4, n]: Exports rotation occured WRT to base frame during reconstruction of SLAM
            np.ndarray: [h, w, d]: image.shape: RGB array of the image
            np.ndarray: [h, w]: depth.shape: Depth array of the imagenp.ndarray: [3, n]: Exports 3D points converted from Depth Image
            np.ndarray: [3, n]: Exports RGB data for corresponding 3D points
            np.ndarray: [3, n]: Exports 3D points converted WRT R,t
        """
        if self.relative:
            self.img_idx, self.odo_xyz, self.odo_wxyz, self._ = self.__readOdometry()
            self.loc_xyz, self.loc_wxyz = self.__globalRT2Local()
        else:
            self.img_idx, self.odo_xyz, self.odo_wxyz, self._ = self.__readOdometry()
        self.images = self.__readRGB()
        self.depths = self.__readDepth()
        self.RGB_res = self.images[0].shape
        self.Depth_res = self.depths[0].shape
        self.orig_ptx, self.color_data = self.__getRGBP3d()
        self.orig_norm = self.__getNomals(self.orig_ptx)
        self.mod_ptx = self.__getModP3d()
        self.mod_norm = self.__getNomals(self.mod_ptx)

    def surface_normal_estimation(self, points, cam_centre, radius=0.05, max_nn=30):
        """ Function to calculate surface normal of 3d points towards camera centre.
        """
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points)
        pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius, max_nn))
        org_surface_normals = np.asarray(pcd.normals)
        direction = points - cam_centre[None, :]
        magnitude_direction = np.linalg.norm(direction, axis=-1)
        direction = direction/magnitude_direction[:, None]
        dirs = np.einsum('ij, ij -> i', org_surface_normals, direction)
        org_surface_normals[dirs>0] = -org_surface_normals[dirs>0]
        return org_surface_normals
    
    def getTofCameraData(self, image_depth = False):
        try:
            self.__getRTABConvertData()
        except:
            print("Error in dataset")
            raise
        tofCameraData = []
        tofCameraDataSegment = []
        tofCameraModPoints = []
        tofCameraOrgPoints = []
        
        rtsCameraData = {}
        rtsCameraData["intrinsic"] = self.intrinsic
        rtsCameraData["intrinsicScaled"] = self.intrinsics_scaled
        rtsCameraData["odo_wxyz"] = self.odo_wxyz
        rtsCameraData["odo_xyz"] = self.odo_xyz
        rtsCameraData["RGB_res"] = self.RGB_res
        rtsCameraData["Depth_res"] = self.Depth_res
        if self.relative:
            rtsCameraData["loc_wxyz"] = self.loc_wxyz
            rtsCameraData["loc_xyz"] = self.loc_xyz
        
        translations = rtsCameraData['odo_xyz']
        for idx in range(len(self.img_idx)):
        #for idx in range(self.startf, self.stopf+self.stepf, self.stepf):
            frame_data = {}
            segment_data = {}
            frame_data["frameNumber"] = int(self.img_idx[idx])
            frame_data["orgPoints"] = self.orig_ptx[idx]
            frame_data["orgNormals"] = self.orig_norm[idx]
            frame_data["modPoints"] = self.mod_ptx[idx]
            frame_data["modNormals"] = self.mod_norm[idx]
            frame_data["orgColorPoints"] = self.color_data[idx]
            modpoints = frame_data['modPoints']
            mod_surface_normals = self.surface_normal_estimation(modpoints, translations[idx])
            frame_data['modSurfaceNormals'] = mod_surface_normals
            if image_depth:
                frame_data["image"] = self.images[idx]
                frame_data["depth"] = self.depths[idx]
            
            segment_data['modPointsSeg'] = self.mod_ptx[idx]
            segment_data['orgPointsSeg'] = self.orig_norm[idx]
            
            tofCameraData.append(frame_data)
            tofCameraModPoints.append(segment_data['modPointsSeg'])
            tofCameraOrgPoints.append(segment_data['orgPointsSeg'])
        '''rtsCameraData = {}
        rtsCameraData["intrinsic"] = self.intrinsic
        rtsCameraData["intrinsicScaled"] = self.intrinsics_scaled
        rtsCameraData["odo_wxyz"] = self.odo_wxyz
        rtsCameraData["odo_xyz"] = self.odo_xyz
        rtsCameraData["RGB_res"] = self.RGB_res
        rtsCameraData["Depth_res"] = self.Depth_res
        if self.relative:
            rtsCameraData["loc_wxyz"] = self.loc_wxyz
            rtsCameraData["loc_xyz"] = self.loc_xyz'''

        return tofCameraData, rtsCameraData, tofCameraModPoints, tofCameraOrgPoints


def getModifiedYRTS(rtsCameraData, rotation, translation, Y_arr):
    """Modify Y set of frames with rotation and translation provided

    Args:
        rtsCameraData (dictionary): Dictionary of RTS Values.
        rotation (np.array [1,4]): Quadranion Rotation [x, y, z, w]
        translation (np.array [1, 3]): Translation [x, y, z]
        Y_arr (np.arrar [1, n]): List of indices for Y frames to be Rotated and translated

    Returns:
        rtsCameraData (dictionary): Dictionary of modified RTS Values.
    """
    for Y_ele in Y_arr:
        rotation = SpatQuadranion(np.roll(rotation,1))
        rtsCameraData["odo_wxyz"][Y_ele] = np.roll((SpatQuadranion(np.roll(rtsCameraData["odo_wxyz"][Y_ele], 1))+ rotation).elements , -1)
        rtsCameraData["odo_xyz"][Y_ele] += translation
    return rtsCameraData

def getModifytofCameraData(rtsCameraData, orgPoints):

    """Get the 3d points modified according to provided modified rotation and translation rtscameradata



    Returns:

        np.ndarray: [tot_frames, 3, n]: Exports 3D points converted WRT R,t

    """

    mod_ptx = []

    for i in range(len(rtsCameraData["odo_wxyz"])):

        rot = SpatQuadranion(np.roll(rtsCameraData["odo_wxyz"][i], 1))

        new_ptx = rot.rotate(orgPoints[i])

        new_ptx = new_ptx + rtsCameraData["odo_xyz"][i]

        mod_ptx.append(new_ptx)

    return mod_ptx

'''def getModifytofCameraData(rtsCameraData, tofCameraData):
    """Get the 3d points modified according to provided modified rotation and translation rtscameradata

    Returns:
        np.ndarray: [tot_frames, 3, n]: Exports 3D points converted WRT R,t
    """
    for i in range(len(rtsCameraData["odo_wxyz"])):
        rot = TooliqaQuaternion(np.roll(rtsCameraData["odo_wxyz"][i], 1))
        new_ptx = rot.rotate(tofCameraData[i]["orgPoints"])
        new_ptx = new_ptx + rtsCameraData["odo_xyz"][i]
        tofCameraData[i]["modPoints"] = new_ptx
    return tofCameraData'''